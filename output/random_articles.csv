feed_title,feed_link,item_title,item_link,item_description,item_pub_date,topic
Talk Python To Me,https://talkpython.fm/,#292 Pythonic identity (auth in Python ecosystem),https://talkpython.fm/episodes/show/292/pythonic-identity-auth-in-python-ecosystem,"So you're excited about that next app you're about to build. You can visualize the APIs with the smooth scalability taking to the mobile apps. You can see how, finally, this time, you'll get deployment right and it'll be pure continuous delivery out of GitHub with zero downtime. What you're probably not dreaming about is writing yet another password reset form and integrating mail capabilities just for this purpose. Or how you'll securely store user accounts the right way this time.Don't worry, we got you covered. Our guests, Christos Matskas and John Patrick Dandison are here to cover a bunch of different libraries and techniques we can use for adding identity to our Python applications.Links from the showChristos on Twitter: @christosmatskasJohn Patrick Dandison on Twitter: @azureandchillshhgit live: shhgit.comTwitch channel for Christos and JP: twitch.tv/425showPasslib & Folding: passlib.readthedocs.ioMicrosoft Authentication Library: github.com/AzureADauthlib - JavaScript Object Signing and Encryption draft implementation: github.comdjango-allauth - Authentication app for Django that ""just works"": github.comdjango-oauth-toolkit - OAuth 2 goodies for Django: github.compython-oauth2 - A fully tested, abstract interface to creating OAuth clients and servers: github.compython-social-auth - An easy-to-setup social authentication mechanism: github.comSponsorsTalk Python TrainingLinode",2020-11-26T00:00:00Z,#datascience #ds #podcast
Data Engineering Podcast,https://www.dataengineeringpodcast.com,Bringing Feature Stores and MLOps to the Enterprise At Tecton - Episode 166,https://www.dataengineeringpodcast.com/tecton-mlops-feature-store-episode-166/#utm_source=rss&utm_medium=rss,"As more organizations are gaining experience with data management and incorporating analytics into their decision making, their next move is to adopt machine learning. In order to make those efforts sustainable, the core capability they need is for data scientists and analysts to be able to build and deploy features in a self service manner. As a result the feature store is becoming a required piece of the data platform. To fill that need Kevin Stumpf and the team at Tecton are building an enterprise feature store as a service. In this episode he explains how his experience building the Michelanagelo platform at Uber has informed the design and architecture of Tecton, how it integrates with your existing data systems, and the elements that are required for well engineered feature store.",2021-01-05T00:44:57Z,#datascience #ds #podcast
Data Engineering Podcast,https://www.dataengineeringpodcast.com,How Shopify Is Building Their Production Data Warehouse Using DBT - Episode 171,https://www.dataengineeringpodcast.com/shopify-data-warehouse-with-dbt-episode-171/#utm_source=rss&utm_medium=rss,"With all of the tools and services available for building a data platform it can be difficult to separate the signal from the noise. One of the best ways to get a true understanding of how a technology works in practice is to hear from people who are running it in production. In this episode Zeeshan Qureshi and Michelle Ark share their experiences using DBT to manage the data warehouse for Shopify. They explain how the structured the project to allow for multiple teams to collaborate in a scalable manner, the additional tooling that they added to address the edge cases that they have run into, and the optimizations that they baked into their continuous integration process to provide fast feedback and reduce costs. This is a great conversation about the lessons learned from real world use of a specific technology and how well it lives up to its promises.",2021-02-09T01:43:41Z,#datascience #ds #podcast
Data Engineering Podcast,https://www.dataengineeringpodcast.com,Low Friction Data Governance With Immuta - Episode 164,https://www.dataengineeringpodcast.com/immuta-data-governance-episode-164/#utm_source=rss&utm_medium=rss,"Data governance is a term that encompasses a wide range of responsibilities, both technical and process oriented. One of the more complex aspects is that of access control to the data assets that an organization is responsible for managing. The team at Immuta has built a platform that aims to tackle that problem in a flexible and maintainable fashion so that data teams can easily integrate authorization, data masking, and privacy enhancing technologies into their data infrastructure. In this episode Steve Touw and Stephen Bailey share what they have built at Immuta, how it is implemented, and how it streamlines the workflow for everyone involved in working with sensitive data. If you are starting down the path of implementing a data governance strategy then this episode will provide a great overview of what is involved.",2020-12-21T23:10:14Z,#datascience #ds #podcast
DEV Community,https://dev.to,Uploading files to node.js server,https://dev.to/mstanciu552/uploading-files-to-node-js-server-4m9i,"This is a guide on how to use the multer library with express.We start with setting up a basic form for uploading a file and other text information(optional).I used React for this tutorial but the same result can be easily achieved with any other framework or with plain JavaScript.      Creating a basic React projectIn order to start we need a working React project. Simply run this command in your terminal to set up a basic React project.npx create-react-app &lt;project_name&gt;    Enter fullscreen mode        Exit fullscreen mode    Note: Replace &lt;project_name&gt; with whatever you want to call your project.To check that everything is working run cd &lt;project_name&gt; and npm start. You should see a boilerplate React app in your browser.      Creating the form for uploadingWe will make a form that will be used to upload files and a title for that file.App.jsimport React from 'react';const App = () =&gt; {    return (        &lt;form&gt;            &lt;input type=""text"" name=""text"" /&gt;            &lt;input type=""file"" name=""file"" /&gt;            &lt;input type=""submit"" value=""Submit"" /&gt;        &lt;/form&gt;);    };export default App;    Enter fullscreen mode        Exit fullscreen mode          Now we will set up a server using multer.jsNote: In order to start run the following command in a folder on the same level as the React project.First initialize a node project in the folder for the server.npm init -y    Enter fullscreen mode        Exit fullscreen mode    2.Then install express and multer using the following command.npm i -D express multer cors body-parser    Enter fullscreen mode        Exit fullscreen mode    3.In your package.json we need to change some things      Add the following to your scripts""scripts"": {    ""start"": ""node index.js""}    Enter fullscreen mode        Exit fullscreen mode          Also add type setting""type"": ""module""    Enter fullscreen mode        Exit fullscreen mode    4.Make a index.js file for the serverimport express from 'express';import bodyparser from 'body-parser';import cors from 'cors';const app = express();app.get('/posts', (req, res) =&gt; {});app.post('/submit', (req, res) =&gt; {});app.listen(3030, () =&gt; console.log('server listening on port 3030'));    Enter fullscreen mode        Exit fullscreen mode          We also need to set up some middlewareimport express from 'express';import bodyparser from 'body-parser';import cors from 'cors';const app = express();app.use(cors());app.use(bodyParser.urlencoded({ extended: true }));app.use(bodyParser.json());app.use('/uploads', express.static('./uploads'));app.get('/posts', (req, res) =&gt; {});app.post('/submit', (req, res) =&gt; {});app.listen(3030, () =&gt; console.log('server listening on port 3030'));    Enter fullscreen mode        Exit fullscreen mode    5.Now let's prepare multerimport express from 'express';import bodyparser from 'body-parser';import cors from 'cors';import multer from 'multer';const app = express();app.use(cors());app.use(bodyParser.urlencoded({ extended: true }));app.use(bodyParser.json());var storage = multer.diskStorage({  destination: function (req, file, cb) {    cb(null, './uploads');  },  filename: function (req, file, cb) {    cb(null, file.fieldname + '-' + Date.now() + '.jpg');  },});var upload = multer({ storage: storage });app.use('/uploads', express.static('./uploads'));app.get('/posts', (req, res) =&gt; {});app.post('/submit', upload.single('file'), (req, res) =&gt; {});app.listen(3030, () =&gt; console.log('server listening on port 3030'));    Enter fullscreen mode        Exit fullscreen mode    6.Now make a uploads file right next to the index.js7.Let's set up MongoDBRun this commandnpm i -D mongoose    Enter fullscreen mode        Exit fullscreen mode    index.jsimport express from 'express';import bodyparser from 'body-parser';import cors from 'cors';import multer from 'multer';import mongoose from 'mongoose';const app = express();app.use(cors());app.use(bodyParser.urlencoded({ extended: true }));app.use(bodyParser.json());var storage = multer.diskStorage({  destination: function (req, file, cb) {    cb(null, './uploads');  },  filename: function (req, file, cb) {    cb(null, file.fieldname + '-' + Date.now() + '.jpg');  },});var upload = multer({ storage: storage });mongoose  .connect('mongodb://localhost:27017/multer-test', {    useNewUrlParser: true,    useUnifiedTopology: true,  })  .then(res =&gt; console.log('DB connected'))  .catch(err =&gt; console.error(err));app.use('/uploads', express.static('./uploads'));app.get('/posts', (req, res) =&gt; {});app.post('/submit', upload.single('file'), (req, res) =&gt; {});app.listen(3030, () =&gt; console.log('server listening on port 3030'));    Enter fullscreen mode        Exit fullscreen mode          Now we will create a model for the databasemodels/Test.jsimport mongoose from 'mongoose';const test_schema = new mongoose.Schema({  file_path: {    type: String,    required: true,  },  description: {    type: String,    required: true,  },});export default mongoose.model('Test', test_schema);    Enter fullscreen mode        Exit fullscreen mode    And after that we can use the databaseindex.jsimport express from 'express';import bodyparser from 'body-parser';import cors from 'cors';import multer from 'multer';import mongoose from 'mongoose';import Test from './models/Test.js';const app = express();app.use(cors());app.use(bodyParser.urlencoded({ extended: true }));app.use(bodyParser.json());var storage = multer.diskStorage({  destination: function (req, file, cb) {    cb(null, './uploads');  },  filename: function (req, file, cb) {    cb(null, file.fieldname + '-' + Date.now() + '.jpg');  },});var upload = multer({ storage: storage });mongoose  .connect('mongodb://localhost:27017/multer-test', {    useNewUrlParser: true,    useUnifiedTopology: true,  })  .then(res =&gt; console.log('DB connected'))  .catch(err =&gt; console.error(err));app.use('/uploads', express.static('./uploads'));app.get('/posts', (req, res) =&gt; {    Test.find({})        .then(response =&gt; res.json(response))        .catch(err =&gt; console.error(err));});app.post('/submit', upload.single('file'), (req, res) =&gt; {    const data = new Test({ description: req.body.text, file_path: req.file.path });    data.save()        .then(response =&gt; console.log(response))        .catch(err =&gt; console.error(err));});app.listen(3030, () =&gt; console.log('server listening on port 3030'));    Enter fullscreen mode        Exit fullscreen mode    Note: This completes our server.      Now we will make a request from the server in order to upload a fileBack in our React project we run:npm i -D axios    Enter fullscreen mode        Exit fullscreen mode    src/App.jsimport React, { useRef } from 'react';import axios from 'axios';const App = () =&gt; {    const formRef = useRef(null);    const submit_file = e =&gt; {        e.preventDefault();        const form_data = new FormData(formRef.current);        axios({            url: 'http://localhost:3030/submit',            method: 'post',            headers: { 'Content-Type': 'multipart/form-data' },            data: form_data        })            .then(res =&gt; console.log(res))            .catch(err =&gt; console.error(err));    };    return (        &lt;form onSubmit={submit_file} ref={formRef}&gt;            &lt;input type=""text"" name=""text"" /&gt;            &lt;input type=""file"" name=""file"" /&gt;            &lt;input type=""submit"" value=""Submit"" /&gt;        &lt;/form&gt;);    };export default App;    Enter fullscreen mode        Exit fullscreen mode          Now we can upload files and save their path to the databaseAlso if we want access to our files and the data related to them we can make another axios request to http://localhost:3030/posts.src/App.jsimport React, { useRef, useState, useEffect } from 'react';import axios from 'axios';const App = () =&gt; {    const formRef = useRef(null);    const [data, setData] = useState([]);    useEffect(() =&gt; {        axios.get('http://localhost:3030/posts')            .then(res =&gt; setData(res.data))            .catch(err =&gt; console.error(err));    }, []);    const submit_file = e =&gt; {        e.preventDefault();        const form_data = new FormData(formRef.current);        axios({            url: 'http://localhost:3030/submit',            method: 'post',            headers: { 'Content-Type': 'multipart/form-data' },            data: form_data        })            .then(res =&gt; console.log(res))            .catch(err =&gt; console.error(err));    };    return (        &lt;form onSubmit={submit_file} ref={formRef}&gt;            &lt;input type=""text"" name=""text"" /&gt;            &lt;input type=""file"" name=""file"" /&gt;            &lt;input type=""submit"" value=""Submit"" /&gt;        &lt;/form&gt;);    };export default App;    Enter fullscreen mode        Exit fullscreen mode    Now we have acces to the file path and text within our data array.src/App.jsimport React, { useRef, useState, useEffect } from 'react';import axios from 'axios';const App = () =&gt; {    const formRef = useRef(null);    const [data, setData] = useState([]);    useEffect(() =&gt; {        axios.get('http://localhost:3030/posts')            .then(res =&gt; setData(res.data))            .catch(err =&gt; console.error(err));    }, []);    const submit_file = e =&gt; {        e.preventDefault();        const form_data = new FormData(formRef.current);        axios({            url: 'http://localhost:3030/submit',            method: 'post',            headers: { 'Content-Type': 'multipart/form-data' },            data: form_data        })            .then(res =&gt; console.log(res))            .catch(err =&gt; console.error(err));    };    return (        &lt;&gt;            &lt;form onSubmit={submit_file} ref={formRef}&gt;                &lt;input type=""text"" name=""text"" /&gt;                &lt;input type=""file"" name=""file"" /&gt;                &lt;input type=""submit"" value=""Submit"" /&gt;            &lt;/form&gt;            &lt;div&gt;            {data.map(el =&gt; (                &lt;div key={el._id}&gt;                    &lt;h2&gt;{ el.description }&lt;/h2&gt;                    &lt;img src={`http://localhost:3030/${el.file_path.replace('\\', '/')}`} /&gt;                &lt;/div&gt;            ))}            &lt;/div&gt;        &lt;/&gt;    );};export default App;    Enter fullscreen mode        Exit fullscreen mode    This is it now you can upload files through a form.If you have any questions please address them in the comments.I also have all the source code for a project like this onn my GitHub profile, here.",2021-02-27T18:40:27Z,#datascience #tutorials
Towards Data Science - Medium,https://towardsdatascience.com?source=rss----7f60cf5620c9---4,How do ReLU Neural Networks approximate any continuous function?,https://towardsdatascience.com/how-do-relu-neural-networks-approximate-any-continuous-function-f59ca3cf2c39?source=rss----7f60cf5620c9---4,NA,2021-02-27T22:35:47Z,#datascience #tutorials
R-bloggers,https://www.r-bloggers.com,Spoil your users with an outstanding Shiny UI,http://feedproxy.google.com/~r/RBloggers/~3/7k7dKOFBca8/,"Value the users of your Shiny App: Do not overlook the power of a professional UI.You can have an amazing analysis behind the scenes, but if you don’t have an intuitive and appealing User Interface, your users might not interact with it properly....The post Spoil your users with an outstanding Shiny UI first appeared on R-bloggers.",2021-02-26T07:30:00Z,#datascience #tutorials
Towards Data Science - Medium,https://towardsdatascience.com?source=rss----7f60cf5620c9---4,3 Things I Did to Become a Data Scientist,https://towardsdatascience.com/3-things-i-did-to-become-a-data-scientist-87a57a14de5d?source=rss----7f60cf5620c9---4,&#x2026; at the time of being a Data AnalystContinue reading on Towards Data Science »,2021-02-27T23:28:01Z,#datascience #tutorials
Graphic detail,https://www.economist.com/graphic-detail/,A round-up of our favourite charts of 2020,https://www.economist.com/graphic-detail/2020/12/24/a-round-up-of-our-favourite-charts-of-2020,"Coronavirus may have dominated our data coverage, but it wasn’t the only story",2020-12-24T00:00:00Z,#dataviz
Graphic detail,https://www.economist.com/graphic-detail/,Poland’s coal-fired home heating creates widespread pollution,https://www.economist.com/graphic-detail/2021/01/30/polands-coal-fired-home-heating-creates-widespread-pollution,The government is backing away from coal—but not fast enough,2021-01-30T00:00:00Z,#dataviz
FlowingData,https://flowingdata.com,Simulation for different immunity scenarios,https://flowingdata.com/2021/02/19/simulation-for-different-immunity-scenarios/,"As vaccinations roll out, we work towards herd immunity, there are various challenges&#8230;Tags: coronavirus, herd, immunity, NPR, simulation",2021-02-19T17:28:33Z,#dataviz
Graphic detail,https://www.economist.com/graphic-detail/,Covid-19 cases pass 100m,https://www.economist.com/graphic-detail/2021/01/26/covid-19-cases-pass-100m,"With the true total likely to be far higher, vaccinations still have a long way to go",2021-01-26T00:00:00Z,#dataviz
Freakonomics Radio,http://freakonomics.com/,235. Who Needs Handwriting?,https://omny.fm/shows/freakonomics-radio/who-needs-handwriting,The digital age is making pen and paper seem obsolete. But what are we giving up if we give up on handwriting?,2016-02-11T04:00:00Z,#economics #podcast
Freakonomics Radio,http://freakonomics.com/,"9. Reading, Rockets, and 'Rithmetic",https://omny.fm/shows/freakonomics-radio/reading-rockets-and-rithmetic,"Government and the private sector often feel far apart.  One is filled with compliance-driven bureaucracy.  The other, with market-fueled innovation.  But something is changing in a multi-billion dollar corner of the Department of Education.  It's an experiment, which takes cues from the likes of Google and millionaires who hope to go to the moon.",2010-10-21T02:53:00Z,#economics #podcast
Freakonomics Radio,http://freakonomics.com/,182. How Can Tiny Norway Afford to Buy So Many Teslas?,https://omny.fm/shows/freakonomics-radio/how-can-tiny-norway-afford-to-buy-so-many-teslas,The Norwegian government parleys massive oil wealth into huge subsidies for electric cars. Is that carbon laundering or just pragmatic environmentalism?,2014-10-16T04:00:00Z,#economics #podcast
Freakonomics Radio,http://freakonomics.com/,357. Can an Industrial Giant Become a Tech Darling?,https://omny.fm/shows/freakonomics-radio/can-an-industrial-giant-become-a-tech-darling,"The Ford Motor Company is ditching its legacy sedans, doubling down on trucks, and trying to steer its stock price out of a long skid. But C.E.O. Jim Hackett has even bigger plans: to turn a century-old automaker into the nucleus of a “transportation operating system.” Is Hackett just whistling past the graveyard, or does he see what others can’t?",2018-11-08T04:00:00Z,#economics #podcast
Uber Engineering Blog,https://eng.uber.com,Engineering Failover Handling in Uber’s Mobile Networking Infrastructure,https://eng.uber.com/eng-failover-handling/,"&#160;Millions of users use Uber’s applications everyday across the globe, accessing seamless transportation or meal delivery at the push of a button. To achieve this accessibility at scale, our mobile apps require low-latency and highly reliable network communication, regardless &#8230;The post Engineering Failover Handling in Uber&#8217;s Mobile Networking Infrastructure appeared first on Uber Engineering Blog.",2020-07-14T16:00:12Z,#tech #engineering
Zillow Tech Hub,https://www.zillow.com/tech/,Using SageMaker for Machine Learning Model Deployment with Zillow Floor Plans,https://www.zillow.com/tech/sagemaker-ml-model-deployment-floor-plans/,"In Zillow Floor Plan: Training Models to Detect Windows, Doors and Openings in Panoramas, we described how we trained our ML model to help generate Zillow Floor Plans. In this post we are going to describe how we designed and implemented the infrastructure that would deploy and serve our models. Our goal was to build an [&#8230;]The post Using SageMaker for Machine Learning Model Deployment with Zillow Floor Plans appeared first on Zillow Tech Hub.",2020-11-09T18:49:19Z,#tech #engineering
Uber Engineering Blog,https://eng.uber.com,Announcing a New Framework for Designing Optimal Experiments with Pyro,https://eng.uber.com/oed-pyro-release/,"Experimentation is one of humanity’s principal tools for learning about our complex world. Advances in knowledge from medicine to psychology require a rigorous, iterative process in which we formulate hypotheses and test them by collecting and analyzing new evidence. At &#8230;The post Announcing a New Framework for Designing Optimal Experiments with Pyro appeared first on Uber Engineering Blog.",2020-05-12T16:00:15Z,#tech #engineering
Stories by Pinterest Engineering on Medium,https://medium.com/@Pinterest_Engineering?source=rss-ef81ef829bcb------2,Manas Two-stage Retrieval — The efficient architecture for hierarchical documents,https://medium.com/pinterest-engineering/manas-two-stage-retrieval-the-efficient-architecture-for-hierarchical-documents-dcaba6e78b0d?source=rss-ef81ef829bcb------2,NA,2021-01-29T20:56:28Z,#tech #engineering
Startups – TechCrunch,https://techcrunch.com,Newness raises $3.5 million for its ‘Twitch for beauty streamers’,https://techcrunch.com/2021/02/26/newness-raises-3-5-million-for-its-twitch-for-beauty-streamers/,"Newness, a startup co-founded by former Twitch employees, has raised $3.5 million in a Sequoia-led seed round for its live-streaming platform aimed at beauty creators and their fan communities. Though today&#8217;s creators are not without options when it comes to livestreaming &#8212; Twitch, YouTube, TikTok, Instagram and Facebook are all popular choices &#8212; Newness is [&#8230;]",2021-02-26T15:00:56Z,#tech #news
BBC News - Technology,https://www.bbc.co.uk/news/,Explore the Cairngorms - in Minecraft,https://www.bbc.co.uk/news/uk-scotland-56202505,The landscape has been recreated to help young people understand how to run a national park.,2021-02-25T22:52:29Z,#tech #news
Startups – TechCrunch,https://techcrunch.com,Why are we still dating LinkedIn in 2021?,https://techcrunch.com/2021/02/26/why-are-we-still-dating-linkedin-in-2021/,"Hello and welcome back to Equity, TechCrunch’s venture capital-focused podcast, where we unpack the numbers behind the headlines. Natasha and Danny and Alex and Grace were all here to chat through the week’s biggest tech happenings. Before we get into this week&#8217;s show, make sure to check out all the news here about how Equity is expanding, and becoming even more of [&#8230;]",2021-02-26T15:00:04Z,#tech #news
BBC News - Technology,https://www.bbc.co.uk/news/,Hawk-Eye Live could replace Wimbledon line judges and other news,https://www.bbc.co.uk/news/technology-56026890,BBC Click's Jen Copestake looks at some of the best technology news stories of the week.,2021-02-19T14:53:06Z,#tech #news
