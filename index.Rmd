---
title: "Data Science News"
description: |
  News is broken. Probably because a data scientist somewhere broke it somehow 
  by creating some echo-chamber, personalization models. Well, this site is a 
  data scientist's attempt to de-personalize data science news and just let 
  you know what's happening. 
site: distill::distill_website
---

**Last updated `r format(lubridate::now("US/Pacific"), '%a, %b %d %I:%M %p')`** PST.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
# setwd("~/github/dsnews")
# renv::init()
# renv::activate()
# install.packages('install.load')
# distill needs to be installed, even if not loaded
# install.packages('distill')
install.load::install_load('tidyRSS', 'tidyverse', 'kableExtra', 'aRxiv', 'lubridate', 'magrittr', 'crayon', 'DT', 'rvest', 'stringr', 'crosstalk')

# colors for pander palette
# ggthemes::palette_pander(10)
# "#56B4E9" "#009E73" "#F0E442" "#0072B2" "#D55E00" "#CC79A7" "#999999" "#E69F00"
gray = "#999999"
orange = "#E69F00"
lt_blue ="#56B4E9"
green = "#009E73"
yellow = "#F0E442"
dk_blue = "#0072B2"
dk_orange = "#D55E00"

# other sources:
# twitter: top tweets
# todo: arxiv output

# Learn more about creating websites with Distill at:
# https://rstudio.github.io/distill/website.html

# Learn more about publishing to GitHub Pages at:
# https://rstudio.github.io/distill/publish_website.html#github-pages


```

```{r feeds}

# https://github.com/kilimchoi/engineering-blogs
# https://github.com/kilimchoi/engineering-blogs/blob/master/engineering_blogs.opml

feeds = list(
    'engineering'= c(
        'openai'= 'https://blog.openai.com/rss/',
        'fb'= 'https://research.fb.com/feed/',
        'airbnb-ds'= 'https://medium.com/feed/airbnb-engineering/tagged/data-science',
        'ggl_ai'= 'http://feeds.feedburner.com/blogspot/gJZg',
        'instacart'= ' https://tech.instacart.com/feed',
        'Google Developers'= 'http://feeds.feedburner.com/GDBcode',
        'Google Open Source'= 'http://feeds.feedburner.com/GoogleOpenSourceBlog',
        'fb_code'= 'https://code.fb.com/feed/',
        'uber_ai'= 'https://eng.uber.com/tag/uber-ai-labs/feed',
        'uber_eng'= 'https://eng.uber.com/feed',
        'netflix_tech'= 'https://medium.com/feed/netflix-techblog',
        'pinterest'= 'https://medium.com/feed/@Pinterest_Engineering',
        'sebrash'= 'https://sebastianraschka.com/rss_feed.xml',
        'zillow'= 'https://www.zillow.com/tech/feed/',
        'acing-ai' = 'https://medium.com/feed/acing-ai'
    ),
    'tutorials'= c(
        # 'databricks'= 'https://databricks.com/feed',
        'datacamp'= 'https://www.datacamp.com/community/rss.xml',
        'ml_mast'= 'https://machinelearningmastery.com/blog/feed/',
        'twrds'= 'https://towardsdatascience.com/feed/',
        'devto'= 'https://dev.to/feed',
        # move these to "news"
        'datafloq'='https://datafloq.com/read/feed.rss',
        'kdd'='http://feeds.feedburner.com/kdnuggets-data-mining-analytics',
        'r-bloggers'='https://feeds.feedburner.com/RBloggers'
    ),
    'general'= c(
        'gnews'= 'https://news.google.com/news/rss/?hl=en&amp;ned=us&amp;gl=US&ned=us&gl=US',
        'espn'= 'http://www.espn.com/espn/rss/news',
        'Science'= 'http://feeds.reuters.com/reuters/scienceNews',
        'TopNews'= 'http://feeds.reuters.com/reuters/topNews',
        'World News'= 'http://feeds.reuters.com/Reuters/worldNews',
        'Sports News'= 'http://feeds.reuters.com/reuters/sportsNews',
        'BBC'= 'http://feeds.bbci.co.uk/news/video_and_audio/news_front_page/rss.xml',
        'BBC US'= 'http://feeds.bbci.co.uk/news/video_and_audio/news_front_page/rss.xml?edition=us',
        'BBC International'= 'http://feeds.bbci.co.uk/news/rss.xml?edition=int',
        'Snopes'= 'https://www.snopes.com/feed/'
    ),
    'tech'= c(
      'dataconomy' = 'https://dataconomy.com/feed/',
        'mit'= 'https://www.technologyreview.com/stories.rss',
        'fc'= 'https://www.fastcompany.com/technology/rss',
        # 'reuters'= 'http://feeds.reuters.com/reuters/technologyNews',
        'bbc'= 'http://feeds.bbci.co.uk/news/video_and_audio/technology/rss.xml',
        'tc'= 'https://techcrunch.com/startups/feed/',
        'vb'= 'https://venturebeat.com/feed/'
    ),
    'startups'= c(
        'tim_ferris'= 'https://tim.blog/feed/',
        'avc'= 'http://feeds.feedburner.com/avc',
        'andrew_chen'= 'https://andrewchen.co/feed/',
        'ycombinator'= 'https://blog.ycombinator.com/feed/',
        'A Horowitz'= 'https://a16z.com/feed/',
        'AVC'= 'https://avc.com/feed/',
        # 'Sam Altman'= 'http://blog.samaltman.com/posts.atom',
        'seth_godin' = 'https://seths.blog/feed/'
    ),
    'podcasts'=c(
      'talkpython'= 'https://talkpython.fm/episodes/rss',
      'data_eng_pod'='https://www.dataengineeringpodcast.com/feed/',
      'dataframed'='https://www.datacamp.com/community/rss.xml',
      'freakonomics'='http://feeds.feedburner.com/freakonomicsradio'
    ),
    'religious'= c(
        'lds'= 'https://www.mormonnewsroom.org/rss'
    )
)

```


```{r}
# df = tidyfeed('https://blog.openai.com/rss/')
# df = tidyfeed('https://www.datatau.com/rss/')

loop_feeds <- function(feed) {
  df = data.frame()
  for (f in feed){
    message(blue('Starting:', f))
    # try-catch: https://stackoverflow.com/a/12195574
    df_feed = tryCatch({
      tidyfeed(f)
    }, error=function(cond) {
      message(red$bold("URL does not seem to exist:", f, cond))
      return(NA)
    },
    warning=function(cond) {
      message(cat(red$bold("URL caused a warning:", f)))
      message("Here's the original warning message:")
      message(cond)
      # Choose a return value in case of warning
      return(NULL)
    }, finally={
      message(green("Processed URL:", f))
    }
    )
    # keep relevant names
    
    # print(names(df)); print(names(df_feed))
    if (is.data.frame(df_feed)){
      message(dim(df_feed), paste(names(df_feed), collapse = ', '))
      for (col in names(df)) {
        if (!(col %in% names(df_feed))) {df_feed[col] = NA}
      }
      # standardize the names - different feeds have different names
      if ('entry_title' %in% names(df_feed)) {df_feed$item_title = df_feed$entry_title}
      if ('entry_link' %in% names(df_feed)) {df_feed$item_link = df_feed$entry_link}
      if ('entry_content' %in% names(df_feed)) {df_feed$item_description = df_feed$entry_title}
      if ('entry_last_updated' %in% names(df_feed)) {df_feed$item_pub_date = df_feed$entry_last_updated}
      
      df <- df_feed %>% 
        select(feed_title, feed_link,
               item_title, item_link, item_description, item_pub_date) %>%
        rbind(df, .)
    } else {
      cat('feed did not work: ', red$bold$underline(f))
    }
  }
  return(df)
}

process_feed <- function(df){
  df %>% 
    distinct() %>% # remove duplicated queries
    arrange(desc(item_pub_date)) %>%
    mutate(
      # add + 1 because I was getting dates as -1
      date_diff = round(difftime(Sys.Date() + 1, item_pub_date, unit='days')),
      date_diff = ifelse(date_diff == 0, "", paste0('<span style="color:gray">\n(-', round(date_diff), 'd)</span>')),
      blank_date = paste0('<p style="display:none">', item_pub_date, '</p>'),
      date_fmt = paste0(
        blank_date,
        format(item_pub_date, '%a %m/%d'),
        date_diff
      ),
      blog = cell_spec(feed_title, "html", link=feed_link, new_tab=T),
      # blog = paste0('<a href="', feed_title,  '" color="#fff" background-color:"#999999">'), 
      # blog = cell_spec(feed_title, "html",  link=feed_link,  color="#fff", underline=F, background=gray),
      linked_title = cell_spec(item_title, 'html', link=item_link, new_tab=T),
      post = paste(
        ifelse(
          is.na(item_description) | item_description == item_title, linked_title, 
          paste0(linked_title, 
                 '<details><summary>', 
                 substring(item_description, 1, 100),
                 '</summary>',
                 substring(item_description, 101, 1000000),
                 '</details>')
        )
      ),
      # post = paste0(blank_date, post, " | ", date_fmt, " | ", blog)
      # post = paste(blog, cell_spec(date, 'html', link=item_link), item_description)
      blog = paste0(blank_date, blog, '<br>', date_fmt)
    ) %>%
    mutate(rand=runif(n())) %>%
    select(blog, post, feed_title, rand) 
}
# df1_p <- process_feed(df1)
# make_dt(df1_p)

make_dt <- function(df) {
  
  
  datatable(
    df, 
    escape=F,
    rownames=F,
    colnames = c('Blog', 'Post'),
    # class='compact',
    # extensions='Scroller',
    # search isn't necessary as global search is good enough
    # filter='top',
    options = list(
      # hide random columns
      columnDefs = list(list(visible=FALSE, targets=c(2, 3))),
      pageLength = 10,
      dom = 'ftlp',
      # pageLength = 1000,
      # dom = 'ft',
      lengthMenu = c(10, 50, 10000),
      # deferRender=TRUE,
      # scrollY=300,
      # scroller=TRUE,
      
      # enforce column width
      # autoWidth = TRUE,
      # columnDefs = list(list(width = '50px', targets = c(0, 1))),
      
      # background color
      initComplete = JS(
        "function(settings, json) {",
        paste0("$(this.api().table().header()).css({'background-color': '", dk_blue, "', 'color': '#fff'});"),
        "}"
      )
    )
  )
}
# make_dt(df1_p)

# TODO: try out kable for neat columns (better mobile?)
# kable(list(x, x, x), "html", escape = FALSE) %>%
# kable_styling(bootstrap_options = c("hover", "condensed"))

```



# Tech + Engineering Blogs

```{r ds, layout='l-page'}
df1 <- loop_feeds(feeds$engineering) 
df1_p <- process_feed(df1) 

# https://rstudio.github.io/crosstalk/
sd <- SharedData$new(df1_p)
bscols(
  filter_slider("rand", label="Random article filterer", 
                sd, column=~rand, step=0.01,
                min=0, max=1),
  filter_select("feed", label="Feed", sd, group=~feed_title)
)
make_dt(sd)

```

# Tutorials

```{r tutorials, layout='l-page'}
# add datatau
datatau <- read_html("http://www.datatau.com/rss") %>% 
  html_text() %>% 
  str_split("]]") %>%
  .[[1]] %>%
  str_match(., ">(.*)(https://.*)(http[s]?://.*)") %>% 
  as.data.frame() %>%
  select(V2, V3) %>%
  rename(item_title=V2, item_link=V3) %>%
  drop_na() %>%
  as_tibble() %>%
  mutate(feed_title='DataTau', feed_link='http://www.datatau.com', item_pub_date = now())

df2 <- loop_feeds(feeds$tutorials) 
for (c in names(df2)) {if (!(c %in% names(datatau))) datatau[c] = NA}
df2_plus <- df2 %>% rbind(datatau)
df2_p <- process_feed(df2_plus)

sd <- SharedData$new(df2_p)
bscols(
  filter_slider("rand", label="Random article filterer", 
                sd, column=~rand, step=0.01,
                min=0, max=1),
  filter_select("feed", label="Feed", sd, group=~feed_title)
)
make_dt(sd)



```

```{r}
## DS + tutorials
# kable(list(head(df1_p, 20), head(df2_p, 20)), 'html', escape=F) %>%
  # kable_styling(bootstrap_options = c("hover", "condensed"))
```


# Tech news
```{r tech, layout='l-screen'}
df3 <- loop_feeds(feeds$tech) 
df3_p <- process_feed(df3)
sd <- SharedData$new(df3_p)
bscols(
  filter_slider("rand", label="Random article filterer", 
                sd, column=~rand, step=0.01,
                min=0, max=1),
  filter_select("feed", label="Feed", sd, group=~feed_title)
)
make_dt(sd)
```

# Startup

```{r startup, layout='l-screen'}
df4 <- loop_feeds(feeds$startup) 
df4_p <- process_feed(df4)
sd <- SharedData$new(df4_p)
bscols(
  filter_slider("rand", label="Random article filterer", 
                sd, column=~rand, step=0.01,
                min=0, max=1),
  filter_select("feed", label="Feed", sd, group=~feed_title)
)
make_dt(sd)
```

# Podcasts

```{r podcasts, layout='l-screen'}
df5 <- loop_feeds(feeds$podcasts) 
df5_p <- process_feed(df5)
sd <- SharedData$new(df5_p)
bscols(
  filter_slider("rand", label="Random article filterer", 
                sd, column=~rand, step=0.01,
                min=0, max=1),
  filter_select("feed", label="Feed", sd, group=~feed_title)
)
make_dt(sd)
```


